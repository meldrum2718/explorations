{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14726,
     "status": "ok",
     "timestamp": 1733222669639,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "lX3XpcGSXBIs",
    "outputId": "2eb4192b-c12b-4f6e-f99a-d2ef905f7338"
   },
   "outputs": [],
   "source": [
    "# https://google.github.io/mediapy/mediapy.html\n",
    "# https://einops.rocks/\n",
    "!pip install mediapy einops --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15313,
     "status": "ok",
     "timestamp": 1733222684949,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "VdFQ6c9-Pm4Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import mediapy as media\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "B_m93Ktg4EGh"
   },
   "outputs": [],
   "source": [
    "## utils\n",
    "\n",
    "def inspect(label, im):\n",
    "    \"\"\" Print some basic image stats.\"\"\"\n",
    "    if im is None:\n",
    "      return\n",
    "    print()\n",
    "    print(label + ':')\n",
    "    print('shape:', im.shape)\n",
    "    print('dtype:', im.dtype)\n",
    "    print('max:', torch.max(im))\n",
    "    print('min:', torch.min(im))\n",
    "    if im.dtype == torch.float32:\n",
    "      print('mean:', torch.mean(im))\n",
    "      print('std:', torch.std(im))\n",
    "    print()\n",
    "\n",
    "def ctime_as_fname():\n",
    "    \"\"\" Return time.ctime() formatted well for a file name.\"\"\"\n",
    "    return  time.ctime().replace(' ', '_').replace(':', '.')\n",
    "\n",
    "def torch2np(im):\n",
    "    print('type im', type(im))\n",
    "    if len(im.shape) == 4:\n",
    "        return im.detach().permute(0, 2, 3, 1).cpu().numpy()\n",
    "    if len(im.shape) == 3:\n",
    "        return im.detach().permute(1, 2, 0).cpu().numpy()\n",
    "    if len(im.shape) == 1:\n",
    "        return im.detach().cpu().numpy()\n",
    "    else:\n",
    "        inspect('im', im)\n",
    "        raise Exception\n",
    "\n",
    "def show_tensor(x, max_n_horiz=9, height=75):\n",
    "    \"\"\" Expect x.shape = (B, C, H, W) or (C, H, W) \"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = torch2np(x)\n",
    "    if len(x.shape) == 4:\n",
    "        if max_n_horiz is None:           \n",
    "            media.show_images(x, border=True, height=height)\n",
    "        else:\n",
    "            B = x.shape[0]\n",
    "            idx = 0\n",
    "            while idx < B:\n",
    "                media.show_images(x[idx:idx+max_n_horiz], height=height)\n",
    "                idx += max_n_horiz\n",
    "    else:\n",
    "        media.show_image(x, height=height)\n",
    "\n",
    "def get_video_frames(traj, nrows, ncols, height=200, fps=100):\n",
    "    N, T, H, W = traj.shape\n",
    "    assert (N % nrows) == 0, 'N must be divisible by nrows'\n",
    "    trj = (torch.clip(traj, 0, 1) * 255).byte().cpu().numpy()\n",
    "    # trj = trj.transpose(1, 2, 0, 3).reshape(T, H, -1)\n",
    "    trj = trj.reshape(nrows, ncols, T, H, W).transpose(2, 0, 3, 1, 4).reshape(T, nrows * H, ncols * W)\n",
    "    \n",
    "    frames = [frame for frame in trj]\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "NsZV6omB5ig7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "\n",
      "x:\n",
      "shape: torch.Size([1, 28, 28])\n",
      "dtype: torch.float32\n",
      "max: tensor(1.)\n",
      "min: tensor(0.)\n",
      "mean: tensor(0.1377)\n",
      "std: tensor(0.3125)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"150\" height=\"150\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB7ElEQVR4nO2UP8hxURjAz0VKittd/CuLwSDKICWDDEbdE5OyyMZksTEpg0ky3AwmC2VQdyAKpQwGA5IMhJXrT7crx32H2/flfT/vHzJ93/ebTj3P+XWenvM8APzn70EsFhO/SCQS6XS6Wq1qtdpSqcTzPMuyyWTyNl/ymUiv10ulUofD4XQ6cRz3+Xy30dVqlc1mIYSHw2E4HLbb7dsodtdotVqbzaZSqbwbvV6voVDodDoBADabzXa7nU6n39dLEMRsNkPv6fV6NE2zLMswzPeKu5AkWSgUIpGIYBwMBnK5HABgMpkoinpSCgBQKBQYhlEUhRAKBAI/vyj6Irbf73meF4oNh8Mi0VfJjyGXy1utFkLI4/G8TAoAMBgMDMMsFotisRiNRjHs/p95GAjhbrcTmhaPxzUazWu8ZrO5Xq8L3nw+r9PpXuPFcTwYDF4uF4RQo9F4jVSA4ziEEMdxLpfrbsKns/8nFovF7/fbbDaJRAIAGI/HnU7n+acZjcZcLrder3+P7Pl8pmn6SZ1arY7FYvP5/HYJ9Pt9r9f7jE6lUrnd7tFo9GGnQAifGS2CIMrl8oct1e12SZKUyWQP6+x2e6VSWS6Xt7rj8ZhKpYQV9UPedR9CCCEUzpPJpFarIYQymcxut3v4gf8wb5vwG2+h9UGFAAAAAElFTkSuQmCC\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "x, y = train_set[0]\n",
    "inspect('x', x)\n",
    "media.show_image(x.squeeze(0), height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "fhpEzgwCJqbW"
   },
   "outputs": [],
   "source": [
    "\"\"\" nn.Modules \"\"\"\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "      x = self.conv(x)\n",
    "      x = self.bn(x)\n",
    "      x = self.activation(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, activation=nn.GELU, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=kernel_size)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, in_channels: int, activation=nn.GELU, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=kernel_size,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=in_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # inspect('unflatten.forward initial x:', x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = Conv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = x + self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = DownConv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = UpConv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "        self.activation = activation()\n",
    "        self.fc2 = nn.Linear(in_features=out_channels, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TimeConditionalUNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        H: int,\n",
    "        W: int,\n",
    "        out_channels: int = None,\n",
    "        num_hiddens: int = 64,\n",
    "        activation=nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.D = D = num_hiddens\n",
    "        self.C = C = in_channels\n",
    "        self.C_out = C_out = out_channels if out_channels is not None else in_channels\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        \n",
    "        self.cb1 = ConvBlock(in_channels=C, out_channels=D, activation=activation)\n",
    "        self.db1 = DownBlock(in_channels=D, out_channels=D, activation=activation)\n",
    "        self.db2 = DownBlock(in_channels=D, out_channels=2*D, activation=activation)\n",
    "        self.flatten = Flatten(activation=activation, kernel_size=(H//4, W//4))\n",
    "        self.unflatten = Unflatten(in_channels=2*D, activation=activation, kernel_size=(H//4, W//4))\n",
    "        self.ub2 = UpBlock(in_channels=4*D, out_channels=D, activation=activation)\n",
    "        self.ub1 = UpBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "        self.cb2 = ConvBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "        self.conv_out = nn.Conv2d(in_channels=D, out_channels=C_out, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "        # Time conditioning layers\n",
    "        self.fc_unflat_t = FCBlock(in_channels=1, out_channels=2*D, activation=activation)\n",
    "        self.fc_ub2_t = FCBlock(in_channels=1, out_channels=D, activation=activation)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (B, C, H, W) input tensor.\n",
    "            t: (B,) normalized time tensor.\n",
    "\n",
    "        Returns:\n",
    "            (B, C_out, H, W) output tensor.\n",
    "        \"\"\"\n",
    "        # inspect('x', x)\n",
    "        B, C, H, W = x.shape\n",
    "        assert (C, H, W) == (self.C, self.H, self.W)\n",
    "        t = t.unsqueeze(-1)\n",
    "\n",
    "        unflat_t = self.fc_unflat_t(t).reshape(B, 2*self.D, 1, 1)\n",
    "        ub2_t = self.fc_ub2_t(t).reshape(B, self.D, 1, 1)\n",
    "\n",
    "        x0 = self.cb1(x)\n",
    "        x1 = self.db1(x0)\n",
    "        x2 = self.db2(x1)\n",
    "        flat = self.flatten(x2)\n",
    "        lat2 = self.unflatten(flat)\n",
    "        lat2 = lat2 + unflat_t\n",
    "        lat2 = torch.concat((x2, lat2), dim=1)\n",
    "        lat1 = self.ub2(lat2)\n",
    "\n",
    "        lat1 = lat1 + ub2_t\n",
    "        lat1 = torch.concat((x1, lat1), dim=1)\n",
    "        lat0 = self.ub1(lat1)\n",
    "        lat0 = torch.concat((x0, lat0), dim=1)\n",
    "        lat0 = self.cb2(lat0)\n",
    "        out = self.conv_out(lat0)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class TimeConditionalUNet(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         C: int,\n",
    "#         H: int,\n",
    "#         W: int,\n",
    "#         num_hiddens: int = 64,\n",
    "#         activation=nn.GELU,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.D = D = num_hiddens\n",
    "#         self.C = C\n",
    "#         self.H = H\n",
    "#         self.W = W\n",
    "        \n",
    "#         self.cb1 = ConvBlock(in_channels=C, out_channels=D, activation=activation)\n",
    "#         self.db1 = DownBlock(in_channels=D, out_channels=D, activation=activation)\n",
    "#         self.db2 = DownBlock(in_channels=D, out_channels=2*D, activation=activation)\n",
    "#         self.flatten = Flatten(activation=activation, kernel_size=(H//4, W//4))\n",
    "#         self.unflatten = Unflatten(in_channels=2*D, activation=activation, kernel_size=(H//4, W//4))\n",
    "#         self.ub2 = UpBlock(in_channels=4*D, out_channels=D, activation=activation)\n",
    "#         self.ub1 = UpBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "#         self.cb2 = ConvBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "#         # self.conv_out = Conv(in_channels=D, out_channels=1, activation=activation) ## this line is wrong, line below is correct (think: we dont want to apply an activation to the model outputs, we would like the model to be able to predict arbitrary outputs, not just outpures > -.5 or whatever min_x GELU(x) is)\n",
    "#         self.conv_out = nn.Conv2d(in_channels=D, out_channels=C, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         ## add the time conditional layers\n",
    "#         self.fc_unflat_t = FCBlock(in_channels=1, out_channels=2*D, activation=activation)\n",
    "#         self.fc_ub2_t = FCBlock(in_channels=1, out_channels=D, activation=activation)\n",
    "\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         t: torch.Tensor,\n",
    "#     ) -> torch.Tensor:\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x: (N, C, H, W) input tensor.\n",
    "#             t: (N,) normalized time tensor.\n",
    "\n",
    "#         Returns:\n",
    "#             (N, C, H, W) output tensor.\n",
    "#         \"\"\"\n",
    "#         # inspect('x', x)\n",
    "#         # assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
    "#         N, C, H, W = x.shape\n",
    "#         t = t.unsqueeze(-1)\n",
    "\n",
    "#         unflat_t = self.fc_unflat_t(t).reshape(N, 2*self.D, 1, 1)\n",
    "#         ub2_t = self.fc_ub2_t(t).reshape(N, self.D, 1, 1)\n",
    "\n",
    "#         x0 = self.cb1(x)\n",
    "#         x1 = self.db1(x0)\n",
    "#         x2 = self.db2(x1)\n",
    "#         flat = self.flatten(x2)\n",
    "#         lat2 = self.unflatten(flat)\n",
    "#         lat2 = lat2 + unflat_t\n",
    "#         lat2 = torch.concat((x2, lat2), dim=1)\n",
    "#         lat1 = self.ub2(lat2)\n",
    "#         lat1 = lat1 + ub2_t\n",
    "#         lat1 = torch.concat((x1, lat1), dim=1)\n",
    "#         lat0 = self.ub1(lat1)\n",
    "#         lat0 = torch.concat((x0, lat0), dim=1)\n",
    "#         lat0 = self.cb2(lat0)\n",
    "#         out = self.conv_out(lat0)\n",
    "#         return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class ImageConditionalUNet(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         in_channels: int,\n",
    "#         cond_channels: int,\n",
    "#         num_hiddens: int = 64,\n",
    "#         activation=nn.GELU,\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         D = num_hiddens\n",
    "#         self.D = D\n",
    "        \n",
    "#         # Main input path\n",
    "#         self.cb1 = ConvBlock(in_channels=in_channels, out_channels=D, activation=activation)\n",
    "#         self.db1 = DownBlock(in_channels=D, out_channels=D, activation=activation)\n",
    "#         self.db2 = DownBlock(in_channels=D, out_channels=2*D, activation=activation)\n",
    "#         self.flatten = Flatten(activation=activation)\n",
    "#         self.unflatten = Unflatten(in_channels=2*D, activation=activation)\n",
    "#         self.ub2 = UpBlock(in_channels=4*D, out_channels=D, activation=activation)\n",
    "#         self.ub1 = UpBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "#         self.cb2 = ConvBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "#         self.conv_out = nn.Conv2d(in_channels=D, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         # Conditioning path for image conditioning\n",
    "#         self.cond_cb1 = ConvBlock(in_channels=cond_channels, out_channels=D, activation=activation)\n",
    "#         self.cond_db1 = DownBlock(in_channels=D, out_channels=D, activation=activation)\n",
    "#         self.cond_db2 = DownBlock(in_channels=D, out_channels=2*D, activation=activation)\n",
    "#         self.cond_flatten = Flatten(activation=activation)\n",
    "\n",
    "#         # Time conditioning layers\n",
    "#         self.fc_unflat_t = FCBlock(in_channels=1, out_channels=2*D, activation=activation)\n",
    "#         self.fc_ub2_t = FCBlock(in_channels=1, out_channels=D, activation=activation)\n",
    "\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         x: torch.Tensor,\n",
    "#         t: torch.Tensor,\n",
    "#         cond: torch.Tensor,\n",
    "#     ) -> torch.Tensor:\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             x: (N, C, H, W) input tensor.\n",
    "#             t: (N,) normalized time tensor.\n",
    "#             cond: (N, C_cond, H, W) conditioning tensor.\n",
    "\n",
    "#         Returns:\n",
    "#             (N, C, H, W) output tensor.\n",
    "#         \"\"\"\n",
    "#         # Process main input\n",
    "#         x0 = self.cb1(x)\n",
    "#         x1 = self.db1(x0)\n",
    "#         x2 = self.db2(x1)\n",
    "#         flat_x = self.flatten(x2)\n",
    "\n",
    "#         # Process conditioning input\n",
    "#         cond0 = self.cond_cb1(cond)\n",
    "#         cond1 = self.cond_db1(cond0)\n",
    "#         cond2 = self.cond_db2(cond1)\n",
    "#         flat_cond = self.cond_flatten(cond2)\n",
    "\n",
    "#         # Combine input and conditioning paths\n",
    "#         fused_flat = flat_x + flat_cond  # Alternatively, try concatenation\n",
    "\n",
    "#         # Apply time conditioning\n",
    "#         unflat_t = self.fc_unflat_t(t).reshape(-1, 2*self.D, 1, 1)\n",
    "#         lat2 = self.unflatten(fused_flat) + unflat_t\n",
    "#         lat2 = torch.concat((x2, lat2), dim=1)\n",
    "\n",
    "#         lat1 = self.ub2(lat2)\n",
    "#         ub2_t = self.fc_ub2_t(t).reshape(-1, self.D, 1, 1)\n",
    "#         lat1 = lat1 + ub2_t\n",
    "#         lat1 = torch.concat((x1, lat1), dim=1)\n",
    "\n",
    "#         lat0 = self.ub1(lat1)\n",
    "#         lat0 = torch.concat((x0, lat0), dim=1)\n",
    "#         lat0 = self.cb2(lat0)\n",
    "\n",
    "#         out = self.conv_out(lat0)\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5760,
     "status": "ok",
     "timestamp": 1733222690706,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "-x7T6_Rr6Pfp",
    "outputId": "b81334a8-e548-48ce-bc0b-c22ef5aa3dc3"
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "C = 3\n",
    "H = 64\n",
    "W = 64\n",
    "\n",
    "x = torch.randn(N, C, H, W).to(device)\n",
    "unet = TimeConditionalUNet(in_channels=C, H=H, W=W).to(device)\n",
    "# out = unet(x, torch.zeros(N).expand(-1))\n",
    "t = torch.ones(N, dtype=int).to(device)\n",
    "out = unet(x=x, t=t.to(torch.float32))\n",
    "inspect('x', x)\n",
    "inspect('out', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 5\n",
    "# C = 5\n",
    "# H = 64\n",
    "# W = 64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # x = torch.randn(N, C, H, W).to(device)\n",
    "# # unet = ImageConditionalUNet(in_channels=C, cond_channels=C).to(device)\n",
    "# # # out = unet(x, torch.zeros(N).expand(-1))\n",
    "# # t = torch.ones(N, dtype=int).to(device)\n",
    "# # out = unet(x=x, cond=x, t=t.to(torch.float32))\n",
    "# # inspect('x', x)\n",
    "# # inspect('out', out)\n",
    "\n",
    "\n",
    "# x = torch.randn(N, 1, 28, 28).to(device)  # Main input\n",
    "# cond = torch.randn(N, 1, 28, 28).to(device)  # Conditioning image\n",
    "# # t = torch.rand(N)  # Normalized time step\n",
    "# t = torch.ones(N, dtype=torch.float32).to(device)\n",
    "\n",
    "# model = ImageConditionalUNet(in_channels=1, cond_channels=1, num_hiddens=64)\n",
    "# model = model.to(device)\n",
    "# output = model(x, t, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1733222690847,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "1ZkMoSkG6PYD",
    "outputId": "ba86cae0-8b79-4ea5-d0f6-97ab2f0e7251"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1733222757128,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "yIvMw63T6JkE"
   },
   "outputs": [],
   "source": [
    "### DDPM ###\n",
    "    \n",
    "# @torch.inference_mode()\n",
    "# def tc_ddpm_sample(\n",
    "#     unet: TimeConditionalUNet,\n",
    "#     ddpm_schedule: dict,\n",
    "#     img_wh: tuple[int, int],\n",
    "#     num_ts: int,\n",
    "#     seed: int = 0,\n",
    "#     num_samples: int = 1,\n",
    "# ) -> torch.Tensor:\n",
    "#     \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
    "\n",
    "#     Args:\n",
    "#         unet: TimeConditionalUNet\n",
    "#         ddpm_schedule: dict\n",
    "#         img_wh: (H, W) output image width and height.\n",
    "#         num_ts: int, number of timesteps.\n",
    "#         seed: int, random seed.\n",
    "\n",
    "#     Returns:\n",
    "#         (N, C, H, W) final sample.\n",
    "#     \"\"\"\n",
    "#     unet.eval()\n",
    "#     torch.manual_seed(seed)\n",
    "#     N, C, H, W = num_samples, 1, img_wh[0], img_wh[1]\n",
    "#     x_t = torch.randn(N, C, H, W).to(device)\n",
    "#     traj = [x_t]\n",
    "#     for t_scalar in torch.arange(num_ts - 1, 0, -1).to(device):\n",
    "#         torch.manual_seed(seed)\n",
    "#         if t_scalar > 1:\n",
    "#             z = torch.randn_like(x_t).to(device)\n",
    "#         else:\n",
    "#             z = torch.zeros_like(x_t).to(device)\n",
    "#         t = torch.ones(N, dtype=int).to(device) * t_scalar\n",
    "\n",
    "#         noise_pred = unet(x=x_t, t=t.to(torch.float32)/num_ts)\n",
    "\n",
    "#         a = ddpm_schedule['alphas'].to(device)\n",
    "#         ab = ddpm_schedule['alpha_bars'].to(device)\n",
    "#         b = ddpm_schedule['betas'].to(device)\n",
    "\n",
    "#         clean_est = (x_t - torch.sqrt(1 - ab[t]) * noise_pred) / torch.sqrt(ab[t])\n",
    "\n",
    "#         a0 = torch.sqrt(ab[t-1]) * b[t]\n",
    "#         a1 = torch.sqrt(a[t]) * (1 - ab[t-1])\n",
    "#         x_t = (a0 * clean_est + a1 * x_t) / (1 - ab[t])\n",
    "#         x_t = x_t + torch.sqrt(b[t]) * z\n",
    "#         traj.append(x_t)\n",
    "\n",
    "#         seed += 1\n",
    "#     return x_t, torch.cat(traj, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "class DDPM(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            unet: TimeConditionalUNet,\n",
    "            betas: tuple[float, float] = (1e-4, 0.02),\n",
    "            num_ts: int = 300,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.C, self.H, self.W = unet.C, unet.H, unet.W\n",
    "        self.unet = unet\n",
    "        self.num_ts = num_ts\n",
    "        self.schedule = DDPM.get_schedule(betas[0], betas[1], num_ts)\n",
    "\n",
    "        for k, v in self.schedule.items():\n",
    "            self.register_buffer(k, v, persistent=False)\n",
    "\n",
    "    \n",
    "    def forward(self, x_0: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Algorithm 1 of the DDPM paper.\n",
    "        Args:\n",
    "            x: (N, C, H, W) input tensor.\n",
    "\n",
    "        Returns:\n",
    "            (,) diffusion loss.\n",
    "        \"\"\"\n",
    "        self.unet.train()\n",
    "        \n",
    "        N, C, H, W = x_0.shape\n",
    "        t = torch.randint(low=0, high=self.num_ts, size=(N,), device=device)\n",
    "\n",
    "        noise = torch.randn_like(x_0, device=device)\n",
    "        ab = self.schedule['alpha_bars']\n",
    "        x_t = (\n",
    "            torch.sqrt(ab[t]) * x_0\n",
    "            + torch.sqrt(1 - ab[t]) * noise\n",
    "        )\n",
    "        t = t.to(torch.float32) / self.num_ts  ## note t.unsqueeze(-1) for the FCBlocks\n",
    "        noise_pred = self.unet(x=x_t, t=t)\n",
    "        loss = F.mse_loss(noise, noise_pred)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(\n",
    "        self,\n",
    "        seed: int = 0,\n",
    "        num_samples: int = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
    "    \n",
    "        Args:\n",
    "            seed: int, random seed.\n",
    "    \n",
    "        Returns:\n",
    "            (N, C, H, W) final sample.\n",
    "        \"\"\"\n",
    "        self.unet.eval()\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        N, C, H, W = num_samples, self.C, self.H, self.W\n",
    "        \n",
    "        x_t = torch.randn(N, C, H, W).to(device)\n",
    "        traj = [x_t]\n",
    "        for t_scalar in torch.arange(self.num_ts - 1, 0, -1).to(device):\n",
    "            torch.manual_seed(seed)\n",
    "            if t_scalar > 1:\n",
    "                z = torch.randn_like(x_t).to(device)\n",
    "            else:\n",
    "                z = torch.zeros_like(x_t).to(device)\n",
    "            t = torch.ones(N, dtype=int).to(device) * t_scalar\n",
    "    \n",
    "            noise_pred = self.unet(x=x_t, t=t.to(torch.float32)/self.num_ts)\n",
    "    \n",
    "            a = self.schedule['alphas'].to(device)\n",
    "            ab = self.schedule['alpha_bars'].to(device)\n",
    "            b = self.schedule['betas'].to(device)\n",
    "    \n",
    "            clean_est = (x_t - torch.sqrt(1 - ab[t]) * noise_pred) / torch.sqrt(ab[t])\n",
    "    \n",
    "            a0 = torch.sqrt(ab[t-1]) * b[t]\n",
    "            a1 = torch.sqrt(a[t]) * (1 - ab[t-1])\n",
    "            x_t = (a0 * clean_est + a1 * x_t) / (1 - ab[t])\n",
    "            x_t = x_t + torch.sqrt(b[t]) * z\n",
    "            traj.append(x_t)\n",
    "    \n",
    "            seed += 1\n",
    "        return x_t, torch.cat(traj, dim=1)\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def get_schedule(cls, beta1: float, beta2: float, num_ts: int) -> dict:\n",
    "        \"\"\"Constants for DDPM training and sampling.\n",
    "    \n",
    "        Arguments:\n",
    "            beta1: float, starting beta value.\n",
    "            beta2: float, ending beta value.\n",
    "            num_ts: int, number of timesteps.\n",
    "    \n",
    "        Returns:\n",
    "            dict with keys:\n",
    "                betas: linear schedule of betas from beta1 to beta2.\n",
    "                alphas: 1 - betas.\n",
    "                alpha_bars: cumulative product of alphas.\n",
    "        \"\"\"\n",
    "        assert beta1 < beta2 < 1.0, \"Expect beta1 < beta2 < 1.0.\"\n",
    "        betas = torch.linspace(beta1, beta2, num_ts).reshape(num_ts, 1, 1, 1).to(torch.float32).to(device)\n",
    "        alphas = 1 - betas\n",
    "        alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "        return {\n",
    "            \"betas\": betas.to(device),\n",
    "            \"alphas\": alphas.to(device),\n",
    "            \"alpha_bars\": alpha_bars.to(device),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1733222808606,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "HDtUVagStdTO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1733222837946,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "UdaBSc6hRF3w"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create TimeConditionalUNet DDPM model and train it, or load weights from saved checkpoint. \"\"\"\n",
    "\n",
    "num_epochs = 1\n",
    "num_hiddens = 16\n",
    "batch_size = 128\n",
    "\n",
    "load_from_saved = False\n",
    "epoch_number_str = str(num_epochs)\n",
    "checkpoint_fname_stem = f'data/tcond_unet_optim_epoch' # {epoch_number_str}.pth'\n",
    "checkpoint_fname = f'{checkpoint_fname_stem}{epoch_number_str}.pth'\n",
    "\n",
    "model = TimeConditionalUNet(\n",
    "    in_channels=1,\n",
    "    H=28,\n",
    "    W=28,\n",
    "    num_hiddens=num_hiddens,\n",
    ").to(device)\n",
    "\n",
    "ddpm = DDPM(\n",
    "    unet=model,\n",
    "    betas=(1e-4, 0.2),\n",
    "    num_ts=30,\n",
    ").to(device)\n",
    "\n",
    "gamma = 0.1 ** (1.0 / num_epochs)\n",
    "\n",
    "subset = torch.utils.data.Subset(train_set, list(range(10_000)))\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=subset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(ddpm.parameters(), lr=1e-2)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=gamma)\n",
    "\n",
    "cur_epoch = 0\n",
    "tcond_ddpm_train_losses = []\n",
    "\n",
    "if load_from_saved:\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_fname, weights_only=True)\n",
    "    cur_epoch = checkpoint['epoch'] + 1\n",
    "    tcond_ddpm_train_losses = checkpoint['train_losses']\n",
    "    ddpm.load_state_dict(checkpoint['ddpm_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "\n",
    "for epoch in range(cur_epoch, num_epochs):\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        optimizer.zero_grad() ## .. i initially forgot this line and ended up with train curves that have a distincly oscillitory (underdamped) motion.. interesting..\n",
    "        x = x.to(device)\n",
    "        # x = x*2 - 1 ### affine scaling\n",
    "        loss = ddpm(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tcond_ddpm_train_losses.append(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "        # batch_count += 1\n",
    "        # if batch_count > 100:\n",
    "        #     break\n",
    "    average_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if (epoch % 5 == 0) or (epoch == num_epochs - 1):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'ddpm_state_dict': ddpm.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            'train_losses': tcond_ddpm_train_losses,\n",
    "        }\n",
    "        path = f'{checkpoint_fname_stem}{epoch}.pth'\n",
    "        # path = f'/content/drive/My Drive/cs180_project5/tcond_unet_optim_epoch{epoch}.pth'\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(tcond_ddpm_train_losses, label='Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid('true', which='both')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "# plt.savefig('/content/drive/My Drive/cs180_project5/tcond_ddpm_train_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1733222843926,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "a6uOtDqHXpIN",
    "outputId": "6cb268f2-300c-473c-c497-9114288c1ae1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744,
     "output_embedded_package_id": "1Vjry7PwE_pHLFBEt9Y0O-8FWQdY0DvHp"
    },
    "executionInfo": {
     "elapsed": 11170,
     "status": "ok",
     "timestamp": 1733222893341,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "uihpaK40wcnp",
    "outputId": "f05f6796-db8b-41e2-d60d-a9fcd12dbb4e"
   },
   "outputs": [],
   "source": [
    "### load time conditional ddpm from checkpoint. create sample generation figures and animation\n",
    "# epoch_number_str = '2'\n",
    "# checkpoint_fname = f'data/tcond_unet_optim_epoch{epoch_number_str}.pth'\n",
    "\n",
    "# model = TimeConditionalUNet(\n",
    "#     C=1,\n",
    "#     H=28,\n",
    "#     W=28,\n",
    "#     num_hiddens=num_hiddens,\n",
    "# ).to(device)\n",
    "\n",
    "# ddpm = DDPM(\n",
    "#     unet=model,\n",
    "#     betas=(1e-4, 0.02),\n",
    "#     num_ts=200,\n",
    "# ).to(device)\n",
    "\n",
    "# checkpoint = torch.load(checkpoint_fname, weights_only=True)\n",
    "# ddpm.load_state_dict(checkpoint['ddpm_state_dict'])\n",
    "\n",
    "nrows = 10\n",
    "ncols = 10\n",
    "num_samples = nrows * ncols\n",
    "\n",
    "x_0, traj = ddpm.sample(seed=101, num_samples=num_samples)\n",
    "x_0 = torch.clip(x_0, 0, 1).detach().cpu()\n",
    "traj = torch.clip(traj, 0, 1).detach().cpu()\n",
    "\n",
    "inspect('x0', x_0)\n",
    "inspect('traj', traj)\n",
    "\n",
    "\n",
    "show_tensor(x_0, max_n_horiz=ncols, height=75)\n",
    "media.show_video(\n",
    "    get_video_frames(traj, nrows=nrows, ncols=ncols),\n",
    "    height=75 * nrows,\n",
    "    fps=ddpm.num_ts / 2,\n",
    ")\n",
    "    \n",
    "# media.write_video(f'/content/drive/My Drive/cs180_project5/tcond_ddpm_sample_trajectories_epoch{epoch_number_str}.mp4', frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGKmh20r3O-v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1nZO0PPQ8OD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(3, 3, device=None).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to(None) is x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, 2) == (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1CnyXxgexPj3zPIFQB9ju7SpfqtjFdjId",
     "timestamp": 1731540785502
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
