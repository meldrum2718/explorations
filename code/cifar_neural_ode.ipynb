{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2b6bc4-d0a0-4379-a73f-021bc71c4bcc",
   "metadata": {},
   "source": [
    "# Playing around with a neural ODE for dense image tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d83aa-dca3-414e-a622-d615215a825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchdiffeq import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676f9df-72e0-43c9-957e-e3af92ae88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "\n",
    "def animate_frames(frames: torch.Tensor, draw_func=None):\n",
    "    if draw_func is None:\n",
    "        def draw_func(ax, t, frames):\n",
    "            ax.cla()\n",
    "            ax.imshow(frames[t])\n",
    "            ax.set_title(str(t))\n",
    "    fig, ax = plt.subplots()\n",
    "    f = lambda t: draw_func(ax, t % len(frames), frames)\n",
    "    return FuncAnimation(fig, func=f, frames=len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01787fc7-d5c5-4ad8-becc-ce85ee19bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "tiny_train_size = 1024\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "tiny_train_dataset, _ = random_split(train_dataset, [tiny_train_size, train_size - tiny_train_size])\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "tiny_train_loader = DataLoader(tiny_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2080fa2-4c04-4674-a7a1-514aec4a6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757ed6a-9390-4863-b490-89dfcc77f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# x, y = next(iter(test_loader))\n",
    "# print(x.shape)\n",
    "# # print(x[0])\n",
    "# plt.imshow(x[0].permute(1, 2, 0))\n",
    "# y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab4ebc-d400-499d-acf3-051ddfb2f4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(nn.Module):\n",
    "    \"\"\" Neural ode with i/o. \"\"\"\n",
    "\n",
    "    class Func(nn.Module):\n",
    "        \"\"\" for use as dstate/dt = Func(t, (input, state)) \"\"\"\n",
    "        def __init__(self, d):\n",
    "            super(Node.Func, self).__init__()\n",
    "            self.fc1 = nn.Linear(2*d, 2*d)\n",
    "            self.fc2 = nn.Linear(2*d, d)\n",
    "            self.fc3 = nn.Linear(d, d)\n",
    "\n",
    "        def forward(self, t, x):\n",
    "            \"\"\" x should be (inp, state), with inp.shape = state.shape = (B, d) \"\"\"\n",
    "            x = torch.concat(x, dim=1)\n",
    "            x = F.softplus(self.fc1(x))\n",
    "            x = F.softplus(self.fc2(x))\n",
    "            return self.fc3(x)\n",
    "\n",
    "    def __init__(self, c, h, w):\n",
    "        super(Node, self).__init__()\n",
    "        self.dim = c * h * w\n",
    "        self.dxdt = Node.Func(self.dim)\n",
    "\n",
    "    def forward(self, inp, init_cond=None, t_eval=None, return_trajectories=False, rtol=1e-5, atol=1e-5, method='rk4'):\n",
    "        B, C, H, W = inp.shape\n",
    "\n",
    "        if init_cond is None:\n",
    "            state = torch.randn(B, self.dim, requires_grad=True).to(device)\n",
    "        else:\n",
    "            assert inp.shape == init_cond.shape\n",
    "            state = init_cond.reshape(B, self.dim).to(device)\n",
    "\n",
    "        if t_eval is None:\n",
    "            t_eval = torch.Tensor([0, 1]).to(device)\n",
    "\n",
    "        dxdt = lambda t, state: self.dxdt(t, (inp.view(B, -1), state))\n",
    "        trajectories = odeint(dxdt, state, t=t_eval, rtol=rtol, atol=atol, method=method)\n",
    "        if return_trajectories:\n",
    "            return trajectories.reshape(len(t_eval), B, C, H, W)\n",
    "        return trajectories[0].reshape(B, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184acd1-c338-4134-ba12-870c4f9cc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node(3, 32, 32)\n",
    "model.to(device)\n",
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e9905-4442-4566-a950-876aa8ea7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626161d1-fd14-49c0-81ef-6d920b8022e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    end_time = 7 + 6*torch.rand(1).item() # 10 +/- 3\n",
    "    t_eval = torch.Tensor([0, end_time]).to(device)\n",
    "    for idx, (images, labels) in enumerate(tiny_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        outputs = model(images, t_eval=t_eval)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(tiny_train_loader)\n",
    "    train_losses.append(average_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f},      s/it: {time.time() - t0:.4f}\", end='\\r')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d450e-1f39-477d-a3e6-1e77daa4feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(train_loader)) \n",
    "frame = x[0]\n",
    "inp = frame.reshape(1, *x[0].shape).to(device)\n",
    "\n",
    "end_time = 15\n",
    "trajectories = model(inp, t_eval=torch.linspace(0, end_time, 30).to(device), return_trajectories=True)\n",
    "trajectories = trajectories.detach()\n",
    "\n",
    "plt.imshow(frame.cpu().permute(1, 2, 0))\n",
    "animate_frames(torch.sigmoid(trajectories.cpu().squeeze(1).permute(0, 2, 3, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3e1a91-364e-4aab-8a29-eefb70eac46c",
   "metadata": {},
   "source": [
    "### this doesnt work.. lets take some inspiration from diffusion models, and train on trajectories rather than just final state\n",
    "generate intermediate targets with a reverse gaussain blurring process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5ddb9-bd39-4656-a9a9-5f2929bcf5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f688f-c2b4-47e7-b884-fe2885ec5ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
