{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch2np(im):\n",
    "    print('type im', type(im))\n",
    "    if len(im.shape) == 4:\n",
    "        return im.detach().permute(0, 2, 3, 1).cpu().numpy()\n",
    "    if len(im.shape) == 3:\n",
    "        return im.detach().permute(1, 2, 0).cpu().numpy()\n",
    "    if len(im.shape) == 1:\n",
    "        return im.detach().cpu().numpy()\n",
    "    else:\n",
    "        inspect('im', im)\n",
    "        raise Exception\n",
    "\n",
    "def show_tensor(x, max_n_horiz=9, height=75):\n",
    "    \"\"\" Expect x.shape = (B, C, H, W) or (C, H, W) \"\"\"\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = torch2np(x)\n",
    "    if len(x.shape) == 4:\n",
    "        if max_n_horiz is None:           \n",
    "            media.show_images(x, border=True, height=height)\n",
    "        else:\n",
    "            B = x.shape[0]\n",
    "            idx = 0\n",
    "            while idx < B:\n",
    "                media.show_images(x[idx:idx+max_n_horiz], height=height)\n",
    "                idx += max_n_horiz\n",
    "    else:\n",
    "        media.show_image(x, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14726,
     "status": "ok",
     "timestamp": 1733222669639,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "lX3XpcGSXBIs",
    "outputId": "2eb4192b-c12b-4f6e-f99a-d2ef905f7338"
   },
   "outputs": [],
   "source": [
    "# https://google.github.io/mediapy/mediapy.html\n",
    "# https://einops.rocks/\n",
    "!pip install mediapy einops --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15313,
     "status": "ok",
     "timestamp": 1733222684949,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "VdFQ6c9-Pm4Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import mediapy as media\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "B_m93Ktg4EGh"
   },
   "outputs": [],
   "source": [
    "## some util functions that I find useful.\n",
    "\n",
    "def inspect(label, im):\n",
    "    \"\"\" Print some basic image stats.\"\"\"\n",
    "    if im is None:\n",
    "      return\n",
    "    print()\n",
    "    print(label + ':')\n",
    "    print('shape:', im.shape)\n",
    "    print('dtype:', im.dtype)\n",
    "    print('max:', torch.max(im))\n",
    "    print('min:', torch.min(im))\n",
    "    if im.dtype == torch.float32:\n",
    "      print('mean:', torch.mean(im))\n",
    "      print('std:', torch.std(im))\n",
    "    print()\n",
    "\n",
    "\n",
    "def ctime_as_fname():\n",
    "    \"\"\" Return time.ctime() formatted well for a file name.\"\"\"\n",
    "    return  time.ctime().replace(' ', '_').replace(':', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "NsZV6omB5ig7"
   },
   "outputs": [],
   "source": [
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "print(train_set)\n",
    "\n",
    "x, y = train_set[0]\n",
    "inspect('x', x)\n",
    "media.show_image(x.squeeze(0), height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733222684950,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "fhpEzgwCJqbW"
   },
   "outputs": [],
   "source": [
    "\"\"\" nn.Modules \"\"\"\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "      x = self.conv(x)\n",
    "      x = self.bn(x)\n",
    "      x = self.activation(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=4,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, activation=nn.GELU, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=kernel_size)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self, in_channels: int, activation=nn.GELU, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv = nn.ConvTranspose2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=in_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=kernel_size,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(num_features=in_channels)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # inspect('unflatten.forward initial x:', x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = Conv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = x + self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = DownConv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv1 = Conv(in_channels=in_channels, out_channels=out_channels, activation=activation)\n",
    "        self.conv2 = UpConv(in_channels=out_channels, out_channels=out_channels, activation=activation)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, activation=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_channels, out_features=out_channels)\n",
    "        self.activation = activation()\n",
    "        self.fc2 = nn.Linear(in_features=out_channels, out_features=out_channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimeConditionalUNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        C: int,\n",
    "        H: int,\n",
    "        W: int,\n",
    "        num_hiddens: int = 64,\n",
    "        activation=nn.GELU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        D = num_hiddens\n",
    "        self.D = D\n",
    "        self.cb1 = ConvBlock(in_channels=C, out_channels=D, activation=activation)\n",
    "        self.db1 = DownBlock(in_channels=D, out_channels=D, activation=activation)\n",
    "        self.db2 = DownBlock(in_channels=D, out_channels=2*D, activation=activation)\n",
    "        self.flatten = Flatten(activation=activation, kernel_size=(H//4, W//4))\n",
    "        self.unflatten = Unflatten(in_channels=2*D, activation=activation, kernel_size=(H//4, W//4))\n",
    "        self.ub2 = UpBlock(in_channels=4*D, out_channels=D, activation=activation)\n",
    "        self.ub1 = UpBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "        self.cb2 = ConvBlock(in_channels=2*D, out_channels=D, activation=activation)\n",
    "        # self.conv_out = Conv(in_channels=D, out_channels=1, activation=activation) ## this line is wrong, line below is correct (think: we dont want to apply an activation to the model outputs, we would like the model to be able to predict arbitrary outputs, not just outpures > -.5 or whatever min_x GELU(x) is)\n",
    "        self.conv_out = nn.Conv2d(in_channels=D, out_channels=C, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        ## add the time conditional layers\n",
    "        self.fc_unflat_t = FCBlock(in_channels=1, out_channels=2*D, activation=activation)\n",
    "        self.fc_ub2_t = FCBlock(in_channels=1, out_channels=D, activation=activation)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        t: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (N, C, H, W) input tensor.\n",
    "            t: (N,) normalized time tensor.\n",
    "\n",
    "        Returns:\n",
    "            (N, C, H, W) output tensor.\n",
    "        \"\"\"\n",
    "        # inspect('x', x)\n",
    "        # assert x.shape[-2:] == (28, 28), \"Expect input shape to be (28, 28).\"\n",
    "        N, C, H, W = x.shape\n",
    "        t = t.unsqueeze(-1)\n",
    "\n",
    "        unflat_t = self.fc_unflat_t(t).reshape(N, 2*self.D, 1, 1)\n",
    "        ub2_t = self.fc_ub2_t(t).reshape(N, self.D, 1, 1)\n",
    "\n",
    "        x0 = self.cb1(x)\n",
    "        x1 = self.db1(x0)\n",
    "        x2 = self.db2(x1)\n",
    "        flat = self.flatten(x2)\n",
    "        lat2 = self.unflatten(flat)\n",
    "        lat2 = lat2 + unflat_t\n",
    "        lat2 = torch.concat((x2, lat2), dim=1)\n",
    "        lat1 = self.ub2(lat2)\n",
    "        lat1 = lat1 + ub2_t\n",
    "        lat1 = torch.concat((x1, lat1), dim=1)\n",
    "        lat0 = self.ub1(lat1)\n",
    "        lat0 = torch.concat((x0, lat0), dim=1)\n",
    "        lat0 = self.cb2(lat0)\n",
    "        out = self.conv_out(lat0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5760,
     "status": "ok",
     "timestamp": 1733222690706,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "-x7T6_Rr6Pfp",
    "outputId": "b81334a8-e548-48ce-bc0b-c22ef5aa3dc3"
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "C = 3\n",
    "H = 16\n",
    "W = 16\n",
    "\n",
    "x = torch.randn(N, C, H, W).to(device)\n",
    "unet = TimeConditionalUNet(C=C, H=H, W=W).to(device)\n",
    "# out = unet(x, torch.zeros(N).expand(-1))\n",
    "t = torch.ones(N, dtype=int).to(device)\n",
    "out = unet(x=x, t=t.to(torch.float32))\n",
    "inspect('x', x)\n",
    "inspect('out', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1733222690847,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "1ZkMoSkG6PYD",
    "outputId": "ba86cae0-8b79-4ea5-d0f6-97ab2f0e7251"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1733222757128,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "yIvMw63T6JkE"
   },
   "outputs": [],
   "source": [
    "### DDPM ###\n",
    "\n",
    "\n",
    "def ddpm_schedule(beta1: float, beta2: float, num_ts: int) -> dict:\n",
    "    \"\"\"Constants for DDPM training and sampling.\n",
    "\n",
    "    Arguments:\n",
    "        beta1: float, starting beta value.\n",
    "        beta2: float, ending beta value.\n",
    "        num_ts: int, number of timesteps.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            betas: linear schedule of betas from beta1 to beta2.\n",
    "            alphas: 1 - betas.\n",
    "            alpha_bars: cumulative product of alphas.\n",
    "    \"\"\"\n",
    "    assert beta1 < beta2 < 1.0, \"Expect beta1 < beta2 < 1.0.\"\n",
    "    betas = torch.linspace(beta1, beta2, num_ts).reshape(num_ts, 1, 1, 1).to(torch.float32).to(device)\n",
    "    alphas = 1 - betas\n",
    "    alpha_bars = torch.cumprod(alphas, dim=0)\n",
    "    return {\n",
    "        \"betas\": betas.to(device),\n",
    "        \"alphas\": alphas.to(device),\n",
    "        \"alpha_bars\": alpha_bars.to(device),\n",
    "    }\n",
    "    \n",
    "\n",
    "def tc_ddpm_forward(\n",
    "    unet: TimeConditionalUNet,\n",
    "    ddpm_schedule: dict,\n",
    "    x_0: torch.Tensor,\n",
    "    num_ts: int,\n",
    "    verbose: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Algorithm 1 of the DDPM paper.\n",
    "\n",
    "    Args:\n",
    "        unet: TimeConditionalUNet\n",
    "        ddpm_schedule: dict\n",
    "        x_0: (N, C, H, W) input tensor.\n",
    "        num_ts: int, number of timesteps.\n",
    "    Returns:\n",
    "        (,) diffusion loss.\n",
    "    \"\"\"\n",
    "    unet.train()\n",
    "    N, C, H, W = x_0.shape\n",
    "    t = torch.randint(low=0, high=num_ts, size=(N,), device=device)\n",
    "\n",
    "    noise = torch.randn_like(x_0, device=device)\n",
    "    ab = ddpm_schedule['alpha_bars']\n",
    "    x_t = (\n",
    "        torch.sqrt(ab[t]) * x_0\n",
    "        + torch.sqrt(1 - ab[t]) * noise\n",
    "    )\n",
    "    t = t.to(torch.float32) / num_ts  ## note t.unsqueeze(-1) for the FCBlocks\n",
    "    noise_pred = unet(x=x_t, t=t)\n",
    "    loss = F.mse_loss(noise, noise_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def tc_ddpm_sample(\n",
    "    unet: TimeConditionalUNet,\n",
    "    ddpm_schedule: dict,\n",
    "    img_wh: tuple[int, int],\n",
    "    num_ts: int,\n",
    "    seed: int = 0,\n",
    "    num_samples: int = 1,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Algorithm 2 of the DDPM paper with classifier-free guidance.\n",
    "\n",
    "    Args:\n",
    "        unet: TimeConditionalUNet\n",
    "        ddpm_schedule: dict\n",
    "        img_wh: (H, W) output image width and height.\n",
    "        num_ts: int, number of timesteps.\n",
    "        seed: int, random seed.\n",
    "\n",
    "    Returns:\n",
    "        (N, C, H, W) final sample.\n",
    "    \"\"\"\n",
    "    unet.eval()\n",
    "    torch.manual_seed(seed)\n",
    "    N, C, H, W = num_samples, 1, img_wh[0], img_wh[1]\n",
    "    x_t = torch.randn(N, C, H, W).to(device)\n",
    "    traj = [x_t]\n",
    "    for t_scalar in torch.arange(num_ts - 1, 0, -1).to(device):\n",
    "        torch.manual_seed(seed)\n",
    "        if t_scalar > 1:\n",
    "            z = torch.randn_like(x_t).to(device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(device)\n",
    "        t = torch.ones(N, dtype=int).to(device) * t_scalar\n",
    "\n",
    "        noise_pred = unet(x=x_t, t=t.to(torch.float32)/num_ts)\n",
    "\n",
    "        a = ddpm_schedule['alphas'].to(device)\n",
    "        ab = ddpm_schedule['alpha_bars'].to(device)\n",
    "        b = ddpm_schedule['betas'].to(device)\n",
    "\n",
    "        clean_est = (x_t - torch.sqrt(1 - ab[t]) * noise_pred) / torch.sqrt(ab[t])\n",
    "\n",
    "        a0 = torch.sqrt(ab[t-1]) * b[t]\n",
    "        a1 = torch.sqrt(a[t]) * (1 - ab[t-1])\n",
    "        x_t = (a0 * clean_est + a1 * x_t) / (1 - ab[t])\n",
    "        x_t = x_t + torch.sqrt(b[t]) * z\n",
    "        traj.append(x_t)\n",
    "\n",
    "        seed += 1\n",
    "    return x_t, torch.cat(traj, dim=1)\n",
    "\n",
    "\n",
    "class TCDDPM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unet: TimeConditionalUNet,\n",
    "        betas: tuple[float, float] = (1e-4, 0.02),\n",
    "        num_ts: int = 300,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.num_ts = num_ts\n",
    "        self.ddpm_schedule = ddpm_schedule(betas[0], betas[1], num_ts)\n",
    "\n",
    "        for k, v in self.ddpm_schedule.items():\n",
    "            self.register_buffer(k, v, persistent=False)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (N, C, H, W) input tensor.\n",
    "\n",
    "        Returns:\n",
    "            (,) diffusion loss.\n",
    "        \"\"\"\n",
    "        return tc_ddpm_forward(\n",
    "            self.unet, self.ddpm_schedule, x, self.num_ts\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(\n",
    "        self,\n",
    "        img_wh: tuple[int, int],\n",
    "        seed: int = 0,\n",
    "        num_samples: int = 1,\n",
    "    ):\n",
    "        return tc_ddpm_sample(\n",
    "            self.unet, self.ddpm_schedule, img_wh, self.num_ts, seed, num_samples=num_samples\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1733222808606,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "HDtUVagStdTO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1733222837946,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "UdaBSc6hRF3w"
   },
   "outputs": [],
   "source": [
    "\"\"\" Create TimeConditionalUNet DDPM model and train it, or load weights from saved checkpoint. \"\"\"\n",
    "\n",
    "num_epochs = 3\n",
    "num_hiddens = 64\n",
    "batch_size = 128\n",
    "\n",
    "load_from_saved = True\n",
    "epoch_number_str = '2'\n",
    "checkpoint_fname_stem = f'data/tcond_unet_optim_epoch' # {epoch_number_str}.pth'\n",
    "checkpoint_fname = f'{checkpoint_fname_stem}{epoch_number_str}.pth'\n",
    "\n",
    "model = TimeConditionalUNet(\n",
    "    C=1,\n",
    "    H=28,\n",
    "    W=28,\n",
    "    num_hiddens=num_hiddens,\n",
    ").to(device)\n",
    "\n",
    "ddpm = TCDDPM(\n",
    "    unet=model,\n",
    "    betas=(1e-4, 0.2),\n",
    "    num_ts=30,\n",
    ").to(device)\n",
    "\n",
    "gamma = 0.1 ** (1.0 / num_epochs)\n",
    "\n",
    "subset = torch.utils.data.Subset(train_set, list(range(1_000)))\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(ddpm.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=gamma)\n",
    "\n",
    "cur_epoch = 0\n",
    "tcond_ddpm_train_losses = []\n",
    "\n",
    "if load_from_saved:\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_fname, weights_only=True)\n",
    "    cur_epoch = checkpoint['epoch'] + 1\n",
    "    tcond_ddpm_train_losses = checkpoint['train_losses']\n",
    "    ddpm.load_state_dict(checkpoint['ddpm_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "\n",
    "for epoch in range(cur_epoch, num_epochs):\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        optimizer.zero_grad() ## .. i initially forgot this line and ended up with train curves that have a distincly oscillitory (underdamped) motion.. interesting..\n",
    "        x = x.to(device)\n",
    "        # x = x*2 - 1 ### affine scaling\n",
    "        loss = ddpm(x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tcond_ddpm_train_losses.append(loss.item())\n",
    "        epoch_loss += loss.item()\n",
    "        # batch_count += 1\n",
    "        # if batch_count > 100:\n",
    "        #     break\n",
    "    average_loss = epoch_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if (epoch % 5 == 0) or (epoch == num_epochs - 1):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'ddpm_state_dict': ddpm.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "            'train_losses': tcond_ddpm_train_losses,\n",
    "        }\n",
    "        path = f'{checkpoint_fname_stem}{epoch}.pth'\n",
    "        # path = f'/content/drive/My Drive/cs180_project5/tcond_unet_optim_epoch{epoch}.pth'\n",
    "        if not os.path.exists('data'):\n",
    "            os.mkdir('data')\n",
    "\n",
    "        torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(tcond_ddpm_train_losses, label='Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid('true', which='both')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.legend()\n",
    "# plt.savefig('/content/drive/My Drive/cs180_project5/tcond_ddpm_train_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1733222843926,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "a6uOtDqHXpIN",
    "outputId": "6cb268f2-300c-473c-c497-9114288c1ae1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 2070,
     "status": "ok",
     "timestamp": 1733222847996,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "Q-Zsj2FJaADj",
    "outputId": "82039fd4-11a5-4557-cb6f-a4c20a6ad346"
   },
   "outputs": [],
   "source": [
    "x_0, traj = ddpm.sample(img_wh=(28, 28), seed=11, num_samples=32)\n",
    "inspect('x0', x_0)\n",
    "show_tensor(torch.clip(x_0, 0, 1).cpu(), max_n_horiz=8, height=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744,
     "output_embedded_package_id": "1Vjry7PwE_pHLFBEt9Y0O-8FWQdY0DvHp"
    },
    "executionInfo": {
     "elapsed": 11170,
     "status": "ok",
     "timestamp": 1733222893341,
     "user": {
      "displayName": "Elliot Meldrum",
      "userId": "03529804471293556491"
     },
     "user_tz": 480
    },
    "id": "uihpaK40wcnp",
    "outputId": "f05f6796-db8b-41e2-d60d-a9fcd12dbb4e"
   },
   "outputs": [],
   "source": [
    "### load time conditional ddpm from checkpoint. create sample generation figures and animation\n",
    "\n",
    "epoch_number_str = '2'\n",
    "checkpoint_fname = f'data/tcond_unet_optim_epoch{epoch_number_str}.pth'\n",
    "\n",
    "model = TimeConditionalUNet(\n",
    "    C=1,\n",
    "    H=28,\n",
    "    W=28,\n",
    "    num_hiddens=num_hiddens,\n",
    ").to(device)\n",
    "\n",
    "ddpm = TCDDPM(\n",
    "    unet=model,\n",
    "    betas=(1e-4, 0.02),\n",
    "    num_ts=200,\n",
    ").to(device)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_fname, weights_only=True)\n",
    "ddpm.load_state_dict(checkpoint['ddpm_state_dict'])\n",
    "\n",
    "n_samples = 32\n",
    "\n",
    "x_0, traj = ddpm.sample(img_wh=(28, 28), seed=11, num_samples=n_samples)\n",
    "inspect('x0', x_0)\n",
    "inspect('traj', traj)\n",
    "show_tensor(torch.clip(x_0, 0, 1).cpu(), max_n_horiz=8, height=75)\n",
    "\n",
    "\n",
    "N, T, H, W = traj.shape\n",
    "nrows = 4\n",
    "assert (N % nrows) == 0, 'N must be divisible by nrows'\n",
    "ncols = N // nrows\n",
    "trj = (torch.clip(traj, 0, 1) * 255).byte().cpu().numpy()\n",
    "# trj = trj.transpose(1, 2, 0, 3).reshape(T, H, -1)\n",
    "trj = trj.reshape(nrows, ncols, T, H, W).transpose(2, 0, 3, 1, 4).reshape(T, nrows * H, ncols * W)\n",
    "\n",
    "frames = [frame for frame in trj]\n",
    "\n",
    "media.show_video(frames, height=200, fps=150)\n",
    "# media.write_video(f'/content/drive/My Drive/cs180_project5/tcond_ddpm_sample_trajectories_epoch{epoch_number_str}.mp4', frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGKmh20r3O-v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1nZO0PPQ8OD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1CnyXxgexPj3zPIFQB9ju7SpfqtjFdjId",
     "timestamp": 1731540785502
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
